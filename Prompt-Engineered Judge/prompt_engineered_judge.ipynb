{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2dbe9a8c3e5c46169ccfc6d8dfcae3bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_98fcf290e5b748188f22b690b6612d2c",
              "IPY_MODEL_fb682c7633654e4aa857e768c0420623",
              "IPY_MODEL_f263a00a33e54770b0b362a49ad805b4"
            ],
            "layout": "IPY_MODEL_3200dc998f7e47a38ef5d19a2b38876b"
          }
        },
        "98fcf290e5b748188f22b690b6612d2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1223c0b5a3734929beca5db49ab82cbb",
            "placeholder": "​",
            "style": "IPY_MODEL_fda84964658b449fb1cc328eb0196dc5",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "fb682c7633654e4aa857e768c0420623": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88c126a8e7e74e4d88f2e11a9d4c7912",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f52acf7c43a54b149f508a9bef9af8a7",
            "value": 2
          }
        },
        "f263a00a33e54770b0b362a49ad805b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b06d05b81b93486d9b886e9d803f553d",
            "placeholder": "​",
            "style": "IPY_MODEL_b7e382fb8953437485e2227503f6d326",
            "value": " 2/2 [00:26&lt;00:00, 12.67s/it]"
          }
        },
        "3200dc998f7e47a38ef5d19a2b38876b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1223c0b5a3734929beca5db49ab82cbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fda84964658b449fb1cc328eb0196dc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88c126a8e7e74e4d88f2e11a9d4c7912": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f52acf7c43a54b149f508a9bef9af8a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b06d05b81b93486d9b886e9d803f553d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7e382fb8953437485e2227503f6d326": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Initialization"
      ],
      "metadata": {
        "id": "_osRsLsaWGqN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QdAwFt_GVYIF"
      },
      "outputs": [],
      "source": [
        "# Block 0: Configuration - EDIT THESE BEFORE RUNNING\n",
        "# Put your real paths here (exact names & folders in your Drive).\n",
        "\n",
        "# Path to training CSV (collaborative dataset). Example filename you gave:\n",
        "TRAIN_PATH = \"/content/drive/MyDrive/Datasets - Training.csv\"\n",
        "\n",
        "# Path to validation CSV (human-labeled validation set, 52 examples)\n",
        "VALIDATION_PATH = \"/content/drive/MyDrive/Datasets - Human-Labeled Validation Set.csv\"\n",
        "\n",
        "# Optional few-shot JSONL (one JSON per line) with curated exemplars:\n",
        "# Each line example:\n",
        "# {\"english\":\"...\", \"filipino\":\"...\", \"criteria\":{\"accuracy\":1,...}, \"explanation\":\"...\"}\n",
        "FEW_SHOT_JSONL = \"/content/drive/MyDrive/few_shot_examples.jsonl\"\n",
        "\n",
        "# Output CSV to write results to:\n",
        "OUTPUT_CSV = \"/content/drive/MyDrive/llm_judge_results.csv\"\n",
        "\n",
        "# Model to use (Hugging Face). Qwen2.5-7B-Instruct recommended for Colab.\n",
        "MODEL_NAME = \"Qwen/Qwen2.5-3B-Instruct\"\n",
        "\n",
        "# Generation params\n",
        "MAX_NEW_TOKENS = 512\n",
        "TEMPERATURE = 0.0   # deterministic; use >0 for robustness checks\n",
        "CONSISTENCY_RUNS = 0  # number of repeated runs per example for consistency test\n",
        "\n",
        "# If your training CSV uses different column names, set these accordingly:\n",
        "COL_ENG = \"English\"\n",
        "COL_CORRECT = \"Filipino-Correct\"\n",
        "COL_FLAWED = \"Filipino-Flawed\"\n",
        "COL_REMARKS = \"Remarks\"\n",
        "COL_CONTRIB = \"Contributor\"\n",
        "\n",
        "# End of Block 0\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch\n",
        "!pip install -q transformers accelerate datasets scipy pandas regex\n",
        "\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "import os, json, re, time, random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import spearmanr\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# Mount Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Quick path checks\n",
        "for p in [TRAIN_PATH, VALIDATION_PATH]:\n",
        "    if not os.path.exists(p):\n",
        "        print(f\"WARNING: path not found: {p}\")\n",
        "    else:\n",
        "        print(f\"Found: {p}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQHjPczSWKqf",
        "outputId": "1c1f0b3b-353a-42c8-b7ea-49ae4b16c90e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Found: /content/drive/MyDrive/Datasets - Training.csv\n",
            "Found: /content/drive/MyDrive/Datasets - Human-Labeled Validation Set.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# JSON extraction + evaluate single pair\n",
        "import re\n",
        "\n",
        "def extract_json_from_text(text):\n",
        "    import json\n",
        "    import re\n",
        "\n",
        "    s = text.strip()\n",
        "    try:\n",
        "        return json.loads(s)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # Find first {...} block (greedy matching to nearest balanced braces)\n",
        "    brace_stack = []\n",
        "    start_idx = None\n",
        "    for i, ch in enumerate(text):\n",
        "        if ch == '{':\n",
        "            if start_idx is None:\n",
        "                start_idx = i\n",
        "            brace_stack.append(ch)\n",
        "        elif ch == '}' and brace_stack:\n",
        "            brace_stack.pop()\n",
        "            if not brace_stack:\n",
        "                candidate = text[start_idx:i+1]\n",
        "                try:\n",
        "                    return json.loads(candidate)\n",
        "                except Exception:\n",
        "                    pass\n",
        "                start_idx = None  # reset and continue searching\n",
        "\n",
        "    return None\n",
        "\n",
        "def normalize_sum_to_label(sum_points):\n",
        "    if sum_points >= 5:\n",
        "        return 5, \"excellent\"\n",
        "    elif sum_points >= 3:\n",
        "        return 3, \"good\"\n",
        "    else:\n",
        "        return 1, \"poor\"\n",
        "\n",
        "REQUIRED_CRITERIA = [\"accuracy\",\"fluency\",\"coherence\",\"cultural_appropriateness\",\"guideline_adherence\",\"completeness\"]\n",
        "\n",
        "def explanation_mentions_most_criteria(explanation_text, threshold=0.8):\n",
        "    if not isinstance(explanation_text, str):\n",
        "        return False\n",
        "    explanation_text = explanation_text.lower()\n",
        "    count = 0\n",
        "    for crit in REQUIRED_CRITERIA:\n",
        "        short = crit.split(\"_\")[0]\n",
        "        if short in explanation_text or crit.replace(\"_\", \" \") in explanation_text:\n",
        "            count += 1\n",
        "    return (count / len(REQUIRED_CRITERIA)) >= threshold\n",
        "\n",
        "def evaluate_pair(\n",
        "    english, filipino, reference=None, tries=2, temp=TEMPERATURE, seed=None, debug=False\n",
        "):\n",
        "    prompt = build_prompt(english, filipino, reference)\n",
        "    last_raw = None\n",
        "\n",
        "    for attempt in range(tries):\n",
        "        if debug:\n",
        "            print(f\"[evaluate_pair] Attempt {attempt + 1}/{tries}, seed={seed}, temp={temp}\")\n",
        "\n",
        "        raw = generate_text(prompt, temperature=temp, seed=seed)\n",
        "        last_raw = raw\n",
        "        parsed = extract_json_from_text(raw)\n",
        "\n",
        "        # If parsing failed, try only once more with temp=0.0 and no retries after that\n",
        "        if parsed is None:\n",
        "            if debug:\n",
        "                print(\"[evaluate_pair] Parsing failed, retrying once with temp=0.0\")\n",
        "            raw = generate_text(prompt, temperature=0.0, seed=seed)\n",
        "            last_raw = raw\n",
        "            parsed = extract_json_from_text(raw)\n",
        "            if parsed is None:\n",
        "                if debug:\n",
        "                    print(\"[evaluate_pair] Parsing failed again, skipping to next attempt\")\n",
        "                # Optional: consider a very short sleep or just continue immediately\n",
        "                time.sleep(0.2)\n",
        "                continue\n",
        "\n",
        "        crit_in = parsed.get(\"criteria\", {})\n",
        "        crit_clean = {}\n",
        "        for k in REQUIRED_CRITERIA:\n",
        "            v = crit_in.get(k, 0)\n",
        "            if isinstance(v, bool):\n",
        "                v = int(v)\n",
        "            try:\n",
        "                vi = int(v)\n",
        "                vi = 1 if vi >= 1 else 0\n",
        "            except Exception:\n",
        "                vi = 0\n",
        "            crit_clean[k] = vi\n",
        "\n",
        "        sum_points = sum(crit_clean.values())\n",
        "        norm_score, label = normalize_sum_to_label(sum_points)\n",
        "\n",
        "        explanation = parsed.get(\"explanation\", \"\")\n",
        "        explanation_ok = explanation_mentions_most_criteria(explanation)\n",
        "\n",
        "        return {\n",
        "            \"criteria\": crit_clean,\n",
        "            \"sum_points\": sum_points,\n",
        "            \"normalized_score\": norm_score,\n",
        "            \"label\": label,\n",
        "            \"explanation\": explanation,\n",
        "            \"explanation_ok\": explanation_ok,\n",
        "            \"raw_output\": raw,\n",
        "        }\n",
        "\n",
        "    # failed all tries\n",
        "    if debug:\n",
        "        print(\"[evaluate_pair] Failed all attempts to parse valid JSON.\")\n",
        "    return {\"error\": \"no valid JSON parsed\", \"raw\": last_raw}"
      ],
      "metadata": {
        "id": "CDkUtxxXW5Mk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# config\n",
        "MAX_NEW_TOKENS = 256\n",
        "TEMPERATURE = 0.7\n",
        "\n",
        "print(\"Loading model:\", MODEL_NAME)\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
        "\n",
        "# Load model\n",
        "try:\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        MODEL_NAME,\n",
        "        device_map=\"auto\",              # Automatically use GPU if available\n",
        "        torch_dtype=torch.float16,      # Use half precision to save some VRAM\n",
        "        trust_remote_code=True\n",
        "    )\n",
        "    print(\"Loaded model in FP16 mode.\")\n",
        "except Exception as e:\n",
        "    print(\"FP16 load failed; falling back to default. Error:\", e)\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        MODEL_NAME,\n",
        "        device_map=\"auto\",\n",
        "        trust_remote_code=True\n",
        "    )\n",
        "\n",
        "# Set to evaluation mode\n",
        "model.eval()\n",
        "DEVICE = next(model.parameters()).device\n",
        "print(\"Model loaded on\", DEVICE)\n",
        "\n",
        "# Text generation function\n",
        "def generate_text(prompt, max_new_tokens=MAX_NEW_TOKENS, temperature=TEMPERATURE, seed=None):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(DEVICE)\n",
        "\n",
        "    if tokenizer.pad_token is None:\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    gen_kwargs = dict(\n",
        "        input_ids=inputs.input_ids,\n",
        "        attention_mask=inputs.attention_mask,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        do_sample=(temperature > 0),\n",
        "        temperature=temperature,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        pad_token_id=tokenizer.pad_token_id,\n",
        "    )\n",
        "\n",
        "    if seed is not None:\n",
        "        torch.manual_seed(seed)\n",
        "        random.seed(seed)\n",
        "        np.random.seed(seed)\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        out = model.generate(**gen_kwargs)\n",
        "\n",
        "    return tokenizer.decode(out[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225,
          "referenced_widgets": [
            "2dbe9a8c3e5c46169ccfc6d8dfcae3bf",
            "98fcf290e5b748188f22b690b6612d2c",
            "fb682c7633654e4aa857e768c0420623",
            "f263a00a33e54770b0b362a49ad805b4",
            "3200dc998f7e47a38ef5d19a2b38876b",
            "1223c0b5a3734929beca5db49ab82cbb",
            "fda84964658b449fb1cc328eb0196dc5",
            "88c126a8e7e74e4d88f2e11a9d4c7912",
            "f52acf7c43a54b149f508a9bef9af8a7",
            "b06d05b81b93486d9b886e9d803f553d",
            "b7e382fb8953437485e2227503f6d326"
          ]
        },
        "id": "kw3WV8LSWw0y",
        "outputId": "11333eb2-b5a8-4bd1-e889-571b38f0814e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model: Qwen/Qwen2.5-3B-Instruct\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2dbe9a8c3e5c46169ccfc6d8dfcae3bf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded model in FP16 mode.\n",
            "Model loaded on cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate Dataset"
      ],
      "metadata": {
        "id": "pP7by_i5WQc_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the collaborative training dataset and validation dataset\n",
        "assert os.path.exists(TRAIN_PATH), f\"Training dataset not found at {TRAIN_PATH}\"\n",
        "df_train = pd.read_csv(TRAIN_PATH)\n",
        "print(\"Training dataset shape:\", df_train.shape)\n",
        "print(\"Training columns:\", df_train.columns.tolist())\n",
        "display(df_train.head())\n",
        "\n",
        "if os.path.exists(VALIDATION_PATH):\n",
        "    df_val = pd.read_csv(VALIDATION_PATH)\n",
        "    print(\"Validation dataset shape:\", df_val.shape)\n",
        "    print(\"Validation columns:\", df_val.columns.tolist())\n",
        "    display(df_val.head())\n",
        "else:\n",
        "    df_val = None\n",
        "    print(\"Validation CSV not found - please upload and set VALIDATION_PATH.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "RheuwILuWNx2",
        "outputId": "7be410f3-22b5-4b91-8e82-746d60cac2f5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset shape: (564, 5)\n",
            "Training columns: ['English', 'Filipino-Correct', 'Filipino-Flawed', 'Remarks', 'Contributor']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                             English  \\\n",
              "0                                Ang gnda na mura pa   \n",
              "1  The Philippines is an archipelago made up of o...   \n",
              "2  Philippines is the world's second-largest arch...   \n",
              "3  Filipino and English are the two official lang...   \n",
              "4  Tagalog is the most widely spoken native langu...   \n",
              "\n",
              "                                    Filipino-Correct  \\\n",
              "0          It so beautiful and it's even affordable.   \n",
              "1  Ang Pilipinas ay isang kapulaang binubuo ng 7,...   \n",
              "2  Ang Pilipinas ang pangalawa sa pinakamalaking ...   \n",
              "3  Filipino at Ingles ang dalawang opisyal na lin...   \n",
              "4  Tagalog ang pinakamalawak at ginagamit na katu...   \n",
              "\n",
              "                                     Filipino-Flawed  \\\n",
              "0                                beautiful and cheap   \n",
              "1  Ang Pilipinas ay isang puno na binubuo ng mahi...   \n",
              "2  Ang Pilipinas ay ang pangalawang malaking isla...   \n",
              "3  Tagalog at Ingles ang dalawa opisyal lingwahe ...   \n",
              "4  Tagalog ay ang pinaka malawak sinasabi katutub...   \n",
              "\n",
              "                                             Remarks  \\\n",
              "0  flawed translation failed to express the 'na' ...   \n",
              "1                                                NaN   \n",
              "2                                                NaN   \n",
              "3                                                NaN   \n",
              "4                                                NaN   \n",
              "\n",
              "                            Contributor  \n",
              "0                       Charibeth Cheng  \n",
              "1  Geena Tibule/Charlyne Arajoy Carabeo  \n",
              "2  Geena Tibule/Charlyne Arajoy Carabeo  \n",
              "3  Geena Tibule/Charlyne Arajoy Carabeo  \n",
              "4  Geena Tibule/Charlyne Arajoy Carabeo  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-68f39a00-97cc-4d1e-84f4-ea6138da0b84\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Filipino-Correct</th>\n",
              "      <th>Filipino-Flawed</th>\n",
              "      <th>Remarks</th>\n",
              "      <th>Contributor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ang gnda na mura pa</td>\n",
              "      <td>It so beautiful and it's even affordable.</td>\n",
              "      <td>beautiful and cheap</td>\n",
              "      <td>flawed translation failed to express the 'na' ...</td>\n",
              "      <td>Charibeth Cheng</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The Philippines is an archipelago made up of o...</td>\n",
              "      <td>Ang Pilipinas ay isang kapulaang binubuo ng 7,...</td>\n",
              "      <td>Ang Pilipinas ay isang puno na binubuo ng mahi...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Geena Tibule/Charlyne Arajoy Carabeo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Philippines is the world's second-largest arch...</td>\n",
              "      <td>Ang Pilipinas ang pangalawa sa pinakamalaking ...</td>\n",
              "      <td>Ang Pilipinas ay ang pangalawang malaking isla...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Geena Tibule/Charlyne Arajoy Carabeo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Filipino and English are the two official lang...</td>\n",
              "      <td>Filipino at Ingles ang dalawang opisyal na lin...</td>\n",
              "      <td>Tagalog at Ingles ang dalawa opisyal lingwahe ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Geena Tibule/Charlyne Arajoy Carabeo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Tagalog is the most widely spoken native langu...</td>\n",
              "      <td>Tagalog ang pinakamalawak at ginagamit na katu...</td>\n",
              "      <td>Tagalog ay ang pinaka malawak sinasabi katutub...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Geena Tibule/Charlyne Arajoy Carabeo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-68f39a00-97cc-4d1e-84f4-ea6138da0b84')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-68f39a00-97cc-4d1e-84f4-ea6138da0b84 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-68f39a00-97cc-4d1e-84f4-ea6138da0b84');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-75ce8b3b-b452-47f2-84ab-f7a97a1f2938\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-75ce8b3b-b452-47f2-84ab-f7a97a1f2938')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-75ce8b3b-b452-47f2-84ab-f7a97a1f2938 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    print(\\\"Validation CSV not found - please upload and set VALIDATION_PATH\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"English\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"The Philippines is an archipelago made up of over 7,640 islands, though only about 2,000 are inhabited.\",\n          \"Tagalog is the most widely spoken native language and forms the basis of Filipino.\",\n          \"Philippines is the world's second-largest archipelago.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Filipino-Correct\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Ang Pilipinas ay isang kapulaang binubuo ng 7,640 na isla, ngunit 2,000 lamang ang tinitirahan\",\n          \"Tagalog ang pinakamalawak at ginagamit na katutubong wika at naging batayan ng Filipino\",\n          \"Ang Pilipinas ang pangalawa sa pinakamalaking kapuluan sa mundo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Filipino-Flawed\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Ang Pilipinas ay isang puno na binubuo ng mahigit 7,640 manok, bagaman halos 2,000 lamang ang tumira.\",\n          \"Tagalog ay ang pinaka malawak sinasabi katutubo lingwahe at mga porma ng batayan ng Filipino\",\n          \"Ang Pilipinas ay ang pangalawang malaking isla sa asya\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Remarks\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"flawed translation failed to express the 'na' and 'pa'\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Contributor\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Geena Tibule/Charlyne Arajoy Carabeo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation dataset shape: (64, 6)\n",
            "Validation columns: ['Source Text (English)', 'Target Text (Filipino)', 'Final Score                          (1 - lowest, 5 - highest)', 'Rater 1 Explanation', 'Rater 2 Explanation', 'Contributor']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                               Source Text (English)  \\\n",
              "0  The children laughed and played under the afte...   \n",
              "1           She took a break to gather her thoughts.   \n",
              "2  The algorithm efficiently identifies patterns ...   \n",
              "3  Data normalization helps improve model perform...   \n",
              "4  alam mo ma'am masaya naman topics natin sa phi...   \n",
              "\n",
              "                              Target Text (Filipino)  \\\n",
              "0  Ang mga bata ay nagtawanan at naglaro sa ilali...   \n",
              "1                Nagpahinga siya para mag-isip-isip.   \n",
              "2  Mabisang kinikilala ng algoritmo ang mga patte...   \n",
              "3  Tumutulong sa pagpabuti ng model ang normalisa...   \n",
              "4  You know, ma'am, we have a lot of fun philosop...   \n",
              "\n",
              "   Final Score                          (1 - lowest, 5 - highest)  \\\n",
              "0                                                4.0                \n",
              "1                                                4.0                \n",
              "2                                                3.0                \n",
              "3                                                5.0                \n",
              "4                                                4.0                \n",
              "\n",
              "                                 Rater 1 Explanation  \\\n",
              "0  Accurate, fluent, and natural translation. Cap...   \n",
              "1  The translation is accurate. It was able to ca...   \n",
              "2  The translation of \"identifies\" as \"kinikilala...   \n",
              "3  The translated text is natural and captures th...   \n",
              "4  flawed translation is close, but failed to tra...   \n",
              "\n",
              "                                 Rater 2 Explanation  \\\n",
              "0  Just slight error due to the literal translati...   \n",
              "1  The translation would have been better if the ...   \n",
              "2  The translation would have been better if the ...   \n",
              "3  The translation didn't literally translated th...   \n",
              "4                                                NaN   \n",
              "\n",
              "                         Contributor  \n",
              "0  Paul Ivan Enclonar/Alonzo Rimando  \n",
              "1  Paul Ivan Enclonar/Alonzo Rimando  \n",
              "2  Paul Ivan Enclonar/Alonzo Rimando  \n",
              "3  Paul Ivan Enclonar/Alonzo Rimando  \n",
              "4                    Charibeth Cheng  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dfe07a47-eb71-4a99-b84b-81c4bd45806d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Source Text (English)</th>\n",
              "      <th>Target Text (Filipino)</th>\n",
              "      <th>Final Score                          (1 - lowest, 5 - highest)</th>\n",
              "      <th>Rater 1 Explanation</th>\n",
              "      <th>Rater 2 Explanation</th>\n",
              "      <th>Contributor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The children laughed and played under the afte...</td>\n",
              "      <td>Ang mga bata ay nagtawanan at naglaro sa ilali...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Accurate, fluent, and natural translation. Cap...</td>\n",
              "      <td>Just slight error due to the literal translati...</td>\n",
              "      <td>Paul Ivan Enclonar/Alonzo Rimando</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>She took a break to gather her thoughts.</td>\n",
              "      <td>Nagpahinga siya para mag-isip-isip.</td>\n",
              "      <td>4.0</td>\n",
              "      <td>The translation is accurate. It was able to ca...</td>\n",
              "      <td>The translation would have been better if the ...</td>\n",
              "      <td>Paul Ivan Enclonar/Alonzo Rimando</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The algorithm efficiently identifies patterns ...</td>\n",
              "      <td>Mabisang kinikilala ng algoritmo ang mga patte...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>The translation of \"identifies\" as \"kinikilala...</td>\n",
              "      <td>The translation would have been better if the ...</td>\n",
              "      <td>Paul Ivan Enclonar/Alonzo Rimando</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Data normalization helps improve model perform...</td>\n",
              "      <td>Tumutulong sa pagpabuti ng model ang normalisa...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>The translated text is natural and captures th...</td>\n",
              "      <td>The translation didn't literally translated th...</td>\n",
              "      <td>Paul Ivan Enclonar/Alonzo Rimando</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>alam mo ma'am masaya naman topics natin sa phi...</td>\n",
              "      <td>You know, ma'am, we have a lot of fun philosop...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>flawed translation is close, but failed to tra...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Charibeth Cheng</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dfe07a47-eb71-4a99-b84b-81c4bd45806d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dfe07a47-eb71-4a99-b84b-81c4bd45806d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dfe07a47-eb71-4a99-b84b-81c4bd45806d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b7a9e1e0-a2cd-4ed9-b09f-483901b80297\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b7a9e1e0-a2cd-4ed9-b09f-483901b80297')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b7a9e1e0-a2cd-4ed9-b09f-483901b80297 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    print(\\\"Validation CSV not found - please upload and set VALIDATION_PATH\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Source Text (English)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"She took a break to gather her thoughts.\",\n          \"alam mo ma'am masaya naman topics natin sa philosophy inaantok lang talaga ko kasi ikaw nagdidiscuss\",\n          \"The algorithm efficiently identifies patterns in large datasets.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Target Text (Filipino)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Nagpahinga siya para mag-isip-isip.\",\n          \"You know, ma'am, we have a lot of fun philosophy topics. I'm just really sleepy in what you're discussing.\",\n          \"Mabisang kinikilala ng algoritmo ang mga pattern sa malalaking dataset.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Final Score                          (1 - lowest, 5 - highest)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7071067811865476,\n        \"min\": 3.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          4.0,\n          3.0,\n          5.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Rater 1 Explanation\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"The translation is accurate. It was able to capture the meaning of the idiom \\\"gather her thoughts\\\", instead of translating it literally to \\\"kumuha ng ideya\\\"\",\n          \"flawed translation is close, but failed to translate that the cause of antok is the ma'am and not the topic.\",\n          \"The translation of \\\"identifies\\\" as \\\"kinikilala\\\" in the context of the sentence is not very accurate. The source text was translated literally.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Rater 2 Explanation\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"The translation would have been better if the translation also captured the gender indicated by the pronoun.\",\n          \"The translation didn't literally translated the text, and the model was able to capture the relationship between data normalization and model performance.\",\n          \"Just slight error due to the literal translation of the \\\"afternoon sun\\\" to \\\"hapon na araw\\\". Afternoon sun means the Sun during the afternoon\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Contributor\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Charibeth Cheng\",\n          \"Paul Ivan Enclonar/Alonzo Rimando\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare few-shot exemplars\n",
        "def load_few_shot_jsonl(path):\n",
        "    shots = []\n",
        "    if os.path.exists(path):\n",
        "        with open(path, 'r', encoding='utf-8') as f:\n",
        "            for line in f:\n",
        "                line = line.strip()\n",
        "                if not line:\n",
        "                    continue\n",
        "                try:\n",
        "                    shots.append(json.loads(line))\n",
        "                except Exception as e:\n",
        "                    print(\"Skipping malformed JSONL line:\", e)\n",
        "    return shots\n",
        "\n",
        "few_shot_shots = load_few_shot_jsonl(FEW_SHOT_JSONL)\n",
        "if len(few_shot_shots) > 0:\n",
        "    print(f\"Loaded {len(few_shot_shots)} curated few-shot exemplars from JSONL.\")\n",
        "else:\n",
        "    print(\"No curated few-shot JSONL found. Sampling 3 examples from training set as exemplars (assumed correct).\")\n",
        "    n = 3\n",
        "    sampled = df_train.sample(n, random_state=42)\n",
        "    few_shot_shots = []\n",
        "    for _, r in sampled.iterrows():\n",
        "        eng = str(r.get(COL_ENG, r.get(\"english\", \"\")))\n",
        "        # prefer correct translation when available for exemplar clarity\n",
        "        fil = str(r.get(COL_CORRECT, r.get(COL_FLAWED, r.get(\"Filipino-Correct\", \"\"))))\n",
        "        few_shot_shots.append({\n",
        "            \"english\": eng,\n",
        "            \"filipino\": fil,\n",
        "            \"criteria\": {\"accuracy\":1,\"fluency\":1,\"coherence\":1,\"cultural_appropriateness\":1,\"guideline_adherence\":1,\"completeness\":1},\n",
        "            \"explanation\": \"Accurate, fluent, coherent, culturally appropriate, follows guidelines, complete.\"\n",
        "        })\n",
        "print(\"Prepared few-shot exemplars:\", len(few_shot_shots))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5wA1skWWkv_",
        "outputId": "577855c8-5996-40c0-860d-0e94adc21446"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 3 curated few-shot exemplars from JSONL.\n",
            "Prepared few-shot exemplars: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt builder\n",
        "import json\n",
        "\n",
        "BASE_PROMPT = r\"\"\"\n",
        "You are a translation judge for English→Filipino. Evaluate the translation using SIX criteria:\n",
        "\n",
        "1) Accuracy: Does the Filipino translation correctly convey the English source text’s meaning, intent, and details? (0 or 1)\n",
        "2) Fluency: Is the translation grammatically correct, natural, and idiomatic in Filipino? (0 or 1)\n",
        "3) Coherence: Does the translation maintain logical flow, context, and structure from the source? (0 or 1)\n",
        "4) Cultural Appropriateness: Does the translation respect Filipino cultural norms, idioms, and sensitivities (e.g., use of \"po\" and \"opo\", regional expressions)? (0 or 1)\n",
        "5) Guideline Adherence: Does the translation follow domain-specific style, terminology, or guidelines (e.g., legal, medical precision)? (0 or 1)\n",
        "6) Completeness: Are all elements of the English source text translated into Filipino without omissions or additions? (0 or 1)\n",
        "\n",
        "For each criterion, assign 0 or 1 (1 = meets the criterion, 0 = does not).\n",
        "\n",
        "Calculate:\n",
        "- sum_points: sum of all criteria points (0 to 6)\n",
        "- normalized_score: an integer from 1 to 5 computed as:\n",
        "  normalized_score = round(1 + 4 * (sum_points / 6))\n",
        "- label: based on normalized_score:\n",
        "    5 → \"excellent\"\n",
        "    4 → \"good\"\n",
        "    3 → \"fair\"\n",
        "    2 → \"poor\"\n",
        "    1 → \"very poor\"\n",
        "\n",
        "Return ONLY valid, parseable JSON with the exact schema below and NOTHING else:\n",
        "\n",
        "{{\n",
        "  \"criteria\": {{\n",
        "    \"accuracy\": 0|1,\n",
        "    \"fluency\": 0|1,\n",
        "    \"coherence\": 0|1,\n",
        "    \"cultural_appropriateness\": 0|1,\n",
        "    \"guideline_adherence\": 0|1,\n",
        "    \"completeness\": 0|1\n",
        "  }},\n",
        "  \"sum_points\": 0-6,\n",
        "  \"normalized_score\": 1-5,\n",
        "  \"label\": \"excellent\"|\"good\"|\"fair\"|\"poor\"|\"very poor\",\n",
        "  \"explanation\": \"<short explanation mentioning each criterion: Accuracy:..., Fluency:..., etc.>\"\n",
        "}}\n",
        "\n",
        "Now evaluate the following translation and respond with ONLY the JSON described above.\n",
        "\n",
        "English: \"{english}\"\n",
        "Filipino: \"{filipino}\"\n",
        "\"\"\"\n",
        "\n",
        "def escape_quotes(text):\n",
        "    if text is None:\n",
        "        return \"\"\n",
        "    return text.replace(\"\\\\\", \"\\\\\\\\\").replace(\"\\\"\", \"\\\\\\\"\").replace(\"\\n\", \"\\\\n\")\n",
        "\n",
        "def build_prompt(english, filipino, reference=None, shots=None):\n",
        "    shot_texts = []\n",
        "    if shots is None:\n",
        "        shots = []\n",
        "    for s in shots:\n",
        "        exemplar_json = {\n",
        "            \"criteria\": s.get(\"criteria\", {\"accuracy\":1,\"fluency\":1,\"coherence\":1,\"cultural_appropriateness\":1,\"guideline_adherence\":1,\"completeness\":1}),\n",
        "        }\n",
        "        exemplar_json[\"sum_points\"] = sum(exemplar_json[\"criteria\"].values())\n",
        "        exemplar_json[\"normalized_score\"] = 5 if exemplar_json[\"sum_points\"]>=5 else (3 if exemplar_json[\"sum_points\"]>=3 else 1)\n",
        "        exemplar_json[\"label\"] = \"excellent\" if exemplar_json[\"normalized_score\"]==5 else (\"good\" if exemplar_json[\"normalized_score\"]==3 else \"poor\")\n",
        "        exemplar_json[\"explanation\"] = s.get(\"explanation\", \"\")\n",
        "        shot_texts.append(\n",
        "            f\"### Example\\nEnglish: \\\"{escape_quotes(s['english'])}\\\"\\nFilipino: \\\"{escape_quotes(s['filipino'])}\\\"\\nDesired JSON output:\\n{json.dumps(exemplar_json, ensure_ascii=False)}\\n\"\n",
        "        )\n",
        "    ref_text = f\"\\nReference: \\\"{escape_quotes(reference)}\\\"\\n\" if reference else \"\\n\"\n",
        "    prompt = BASE_PROMPT + \"\\n\\n\" + \"\\n\".join(shot_texts) + f\"\\n### Now evaluate:\\nEnglish: \\\"{escape_quotes(english)}\\\"\\nFilipino: \\\"{escape_quotes(filipino)}\\\"{ref_text}\\nReturn JSON only.\\n\"\n",
        "    return prompt\n"
      ],
      "metadata": {
        "id": "l22RRpSNWlPH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "assert df_val is not None, \"Validation dataset (df_val) must be loaded to run evaluation.\"\n",
        "\n",
        "# Normalize column names (lowercase, stripped)\n",
        "df_val.columns = [col.strip().lower() for col in df_val.columns]\n",
        "\n",
        "# Drop rows where all columns are empty\n",
        "df_val = df_val.dropna(how='all')\n",
        "\n",
        "def find_column(columns, keywords):\n",
        "    \"\"\"Find first column containing all keywords (case-insensitive).\"\"\"\n",
        "    for col in columns:\n",
        "        if all(k.lower() in col for k in keywords):\n",
        "            return col\n",
        "    return None\n",
        "\n",
        "col_eng = find_column(df_val.columns, [\"source\", \"english\"])\n",
        "col_fil = find_column(df_val.columns, [\"target\", \"filipino\"])\n",
        "col_score = find_column(df_val.columns, [\"final\", \"score\"])\n",
        "\n",
        "assert col_eng is not None and col_fil is not None, \"Could not find English/Filipino columns in df_val.\"\n",
        "\n",
        "CHUNK_SIZE = 10\n",
        "all_results = []\n",
        "processed_count = 0\n",
        "start_time = time.time()\n",
        "num_rows = len(df_val)\n",
        "\n",
        "OUTPUT_JSONL = \"/content/drive/MyDrive/results.jsonl\"  # JSON Lines file path\n",
        "\n",
        "with open(OUTPUT_JSONL, \"w\", encoding=\"utf-8\") as f:\n",
        "    pass\n",
        "\n",
        "for idx, row in df_val.iterrows():\n",
        "    try:\n",
        "        eng_text = row[col_eng]\n",
        "        fil_text = row[col_fil]\n",
        "        reference = None  # No reference column available\n",
        "\n",
        "        # Skip if either English or Filipino text is empty or not a string\n",
        "        if not (isinstance(eng_text, str) and eng_text.strip()) or not (isinstance(fil_text, str) and fil_text.strip()):\n",
        "            continue\n",
        "\n",
        "        sums = []\n",
        "        scores = []\n",
        "        raw_outputs_list = []\n",
        "        explanation_ok_count = 0\n",
        "\n",
        "        if CONSISTENCY_RUNS >= 1:\n",
        "            # Main evaluation run\n",
        "            seed = random.randint(1, 2**30 - 1)\n",
        "            res = evaluate_pair(eng_text, fil_text, reference=reference, tries=1, temp=TEMPERATURE, seed=seed)\n",
        "\n",
        "            # Additional consistency runs\n",
        "            for _ in range(CONSISTENCY_RUNS):\n",
        "                seed = random.randint(1, 2**30 - 1)\n",
        "                tmp_res = evaluate_pair(eng_text, fil_text, reference=reference, tries=1, temp=TEMPERATURE, seed=seed)\n",
        "                raw_outputs_list.append(tmp_res.get(\"raw_output\", tmp_res.get(\"raw\", \"\"))[:500])\n",
        "                if tmp_res.get(\"sum_points\") is not None:\n",
        "                    sums.append(tmp_res[\"sum_points\"])\n",
        "                    scores.append(tmp_res[\"normalized_score\"])\n",
        "                if tmp_res.get(\"explanation_ok\"):\n",
        "                    explanation_ok_count += 1\n",
        "        else:\n",
        "            # No consistency runs, just main tries=2\n",
        "            res = evaluate_pair(eng_text, fil_text, reference=reference, tries=2)\n",
        "            raw_outputs_list = []\n",
        "            sums = []\n",
        "            scores = []\n",
        "            explanation_ok_count = 0\n",
        "\n",
        "        # Compute variation percentage for consistency sums if applicable\n",
        "        variation_pct = None\n",
        "        if len(sums) >= 2:\n",
        "            mean = np.mean(sums)\n",
        "            std = np.std(sums)\n",
        "            variation_pct = (std / mean * 100) if mean != 0 else (std * 100)\n",
        "\n",
        "        # Parse human score safely\n",
        "        human_score = None\n",
        "        if col_score and not pd.isna(row[col_score]):\n",
        "            try:\n",
        "                human_score = int(row[col_score])\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        all_results.append({\n",
        "            \"idx\": idx,\n",
        "            \"english\": eng_text,\n",
        "            \"filipino\": fil_text,\n",
        "            \"reference\": reference,\n",
        "            \"model_criteria\": res.get(\"criteria\"),\n",
        "            \"model_sum\": res.get(\"sum_points\"),\n",
        "            \"model_score\": res.get(\"normalized_score\"),\n",
        "            \"model_label\": res.get(\"label\"),\n",
        "            \"model_explanation\": res.get(\"explanation\"),\n",
        "            \"explanation_ok\": res.get(\"explanation_ok\"),\n",
        "            \"consistency_sums\": sums,\n",
        "            \"consistency_scores\": scores,\n",
        "            \"consistency_variation_pct\": variation_pct,\n",
        "            \"raw_outputs\": raw_outputs_list,\n",
        "            \"human_score\": human_score\n",
        "        })\n",
        "\n",
        "        processed_count += 1\n",
        "\n",
        "        # Periodic progress update\n",
        "        if processed_count % 5 == 0 or processed_count == num_rows:\n",
        "            elapsed = time.time() - start_time\n",
        "            avg_per_row = elapsed / processed_count\n",
        "            est_total = avg_per_row * num_rows\n",
        "            est_remaining = est_total - elapsed\n",
        "            print(f\"⏳ Processed {processed_count}/{num_rows} rows. \"\n",
        "                  f\"Elapsed: {elapsed:.1f}s, Avg/row: {avg_per_row:.2f}s, Est remaining: {est_remaining:.1f}s\")\n",
        "\n",
        "\n",
        "\n",
        "        # Save chunks to JSON Lines file\n",
        "        if processed_count % CHUNK_SIZE == 0:\n",
        "            with open(OUTPUT_JSONL, \"a\", encoding=\"utf-8\") as f:\n",
        "                for record in all_results:\n",
        "                    f.write(json.dumps(record) + \"\\n\")\n",
        "            all_results = []\n",
        "            print(f\"💾 Saved {processed_count} rows so far...\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Error processing row {idx}: {e}\")\n",
        "        continue\n",
        "\n",
        "# Save leftover rows after loop\n",
        "if all_results:\n",
        "    with open(OUTPUT_JSONL, \"a\", encoding=\"utf-8\") as f:\n",
        "        for record in all_results:\n",
        "            f.write(json.dumps(record) + \"\\n\")\n",
        "    print(f\"💾 Saved final chunk. Total rows processed: {processed_count}\")\n",
        "\n",
        "print(f\"📂 All evaluations saved to: {OUTPUT_JSONL}\")\n",
        "\n",
        "# Load JSON Lines for analysis\n",
        "out_df = pd.read_json(OUTPUT_JSONL, lines=True)\n",
        "\n",
        "# Compute Spearman correlation if data is sufficient\n",
        "valid_rows = out_df.dropna(subset=[\"human_score\", \"model_score\"])\n",
        "if len(valid_rows) >= 2:\n",
        "    rho, pval = spearmanr(valid_rows[\"human_score\"].astype(float), valid_rows[\"model_score\"].astype(float))\n",
        "    print(f\"📊 Spearman rho = {rho:.4f} (p={pval:.4g}), n={len(valid_rows)}\")\n",
        "else:\n",
        "    print(\"⚠️ Not enough pairs to compute Spearman correlation.\")\n",
        "\n",
        "print(f\"🧠 Explainability coverage: {out_df['explanation_ok'].mean():.3f}\")\n",
        "print(f\"📈 Average consistency variation %: {out_df['consistency_variation_pct'].dropna().mean():.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRWcgkcNXAM3",
        "outputId": "b71c3f32-55d2-4657-aa39-4b55358a78dc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ Processed 5/57 rows. Elapsed: 153.7s, Avg/row: 30.75s, Est remaining: 1599.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ Processed 10/57 rows. Elapsed: 257.7s, Avg/row: 25.77s, Est remaining: 1211.1s\n",
            "💾 Saved 10 rows so far...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ Processed 15/57 rows. Elapsed: 322.3s, Avg/row: 21.49s, Est remaining: 902.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ Processed 20/57 rows. Elapsed: 504.6s, Avg/row: 25.23s, Est remaining: 933.6s\n",
            "💾 Saved 20 rows so far...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ Processed 25/57 rows. Elapsed: 609.0s, Avg/row: 24.36s, Est remaining: 779.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ Processed 30/57 rows. Elapsed: 751.7s, Avg/row: 25.06s, Est remaining: 676.5s\n",
            "💾 Saved 30 rows so far...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ Processed 35/57 rows. Elapsed: 933.2s, Avg/row: 26.66s, Est remaining: 586.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ Processed 40/57 rows. Elapsed: 1154.0s, Avg/row: 28.85s, Est remaining: 490.4s\n",
            "💾 Saved 40 rows so far...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ Processed 45/57 rows. Elapsed: 1332.5s, Avg/row: 29.61s, Est remaining: 355.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ Processed 50/57 rows. Elapsed: 1472.3s, Avg/row: 29.45s, Est remaining: 206.1s\n",
            "💾 Saved 50 rows so far...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ Processed 55/57 rows. Elapsed: 1574.7s, Avg/row: 28.63s, Est remaining: 57.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ Processed 57/57 rows. Elapsed: 1600.0s, Avg/row: 28.07s, Est remaining: 0.0s\n",
            "💾 Saved final chunk. Total rows processed: 57\n",
            "📂 All evaluations saved to: /content/drive/MyDrive/results.jsonl\n",
            "📊 Spearman rho = -0.0344 (p=0.8445), n=35\n",
            "🧠 Explainability coverage: 0.971\n",
            "📈 Average consistency variation %: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate Translation Pair"
      ],
      "metadata": {
        "id": "lGGSQVPlX2X4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import random\n",
        "\n",
        "# ---- Input: your single pair ----\n",
        "english_text = \"Hello, how are you?\"\n",
        "filipino_text = \"Kamusta, kumusta ka?\"\n",
        "reference_text = None  # optional, can be left as None\n",
        "\n",
        "# ---- Parameters ----\n",
        "CONSISTENCY_RUNS = 0   # no extra runs\n",
        "TEMPERATURE = 0.7\n",
        "\n",
        "# ---- Evaluation ----\n",
        "sums = []\n",
        "scores = []\n",
        "raw_outputs_list = []\n",
        "explanation_ok_count = 0\n",
        "\n",
        "# Only main evaluation run\n",
        "seed = random.randint(1, 2**30 - 1)\n",
        "res = evaluate_pair(\n",
        "    english_text,\n",
        "    filipino_text,\n",
        "    reference=reference_text,\n",
        "    tries=1,\n",
        "    temp=TEMPERATURE,\n",
        "    seed=seed,\n",
        "    debug=True\n",
        ")\n",
        "\n",
        "# ---- Output results ----\n",
        "result_record = {\n",
        "    \"english\": english_text,\n",
        "    \"filipino\": filipino_text,\n",
        "    \"reference\": reference_text,\n",
        "    \"model_criteria\": res.get(\"criteria\"),\n",
        "    \"model_sum\": res.get(\"sum_points\"),\n",
        "    \"model_score\": res.get(\"normalized_score\"),\n",
        "    \"model_label\": res.get(\"label\"),\n",
        "    \"model_explanation\": res.get(\"explanation\"),\n",
        "    \"explanation_ok\": res.get(\"explanation_ok\"),\n",
        "    \"raw_outputs\": raw_outputs_list,\n",
        "}\n",
        "\n",
        "OUTPUT_FILE = \"/content/drive/MyDrive/single_pair_result.json\"\n",
        "with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(result_record, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"💾 Result saved to: {OUTPUT_FILE}\")\n",
        "\n",
        "print(json.dumps(result_record, indent=2, ensure_ascii=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuHWBBSiX1sY",
        "outputId": "50f3e6ec-10f9-4ffd-932c-c244fac7e8a5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[evaluate_pair] Attempt 1/1, seed=88914704, temp=0.7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[evaluate_pair] Parsing failed, retrying once with temp=0.0\n",
            "💾 Result saved to: /content/drive/MyDrive/single_pair_result.json\n",
            "{\n",
            "  \"english\": \"Hello, how are you?\",\n",
            "  \"filipino\": \"Kamusta, kumusta ka?\",\n",
            "  \"reference\": null,\n",
            "  \"model_criteria\": {\n",
            "    \"accuracy\": 0,\n",
            "    \"fluency\": 1,\n",
            "    \"coherence\": 1,\n",
            "    \"cultural_appropriateness\": 1,\n",
            "    \"guideline_adherence\": 1,\n",
            "    \"completeness\": 1\n",
            "  },\n",
            "  \"model_sum\": 5,\n",
            "  \"model_score\": 5,\n",
            "  \"model_label\": \"excellent\",\n",
            "  \"model_explanation\": \"Accuracy is 0 because 'Kumusta' is a greeting but doesn't fully capture the full meaning of 'Hello, how are you?'. Fluency, coherence, cultural appropriateness, and guideline adherence are all 1 as the translation is grammatically correct, maintains context, respects cultural norms, and follows the greeting convention. Completeness is 1 as all elements are included.\",\n",
            "  \"explanation_ok\": true,\n",
            "  \"consistency_sums\": [],\n",
            "  \"consistency_scores\": [],\n",
            "  \"consistency_variation_pct\": null,\n",
            "  \"raw_outputs\": []\n",
            "}\n"
          ]
        }
      ]
    }
  ]
}